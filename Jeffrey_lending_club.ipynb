{
	"cells": [{
		"cell_type": "code",
		"source": ["# Do not delete or change this cell\n\nimport os\n\n# Define a function to determine if we are running on data bricks\n# Return true if running in the data bricks environment, false otherwise\ndef is_databricks():\n    # get the databricks runtime version\n    db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n    \n    # if running on data bricks\n    if db_env != None:\n        return True\n    else:\n        return False\n\n# Define a function to read the data file.  The full path data file name is constructed\n# by checking runtime environment variables to determine if the runtime environment is \n# databricks, or a student's personal computer.  The full path file name is then\n# constructed based on the runtime env.\n# \n# Params\n#   data_file_name: The base name of the data file to load\n# \n# Returns the full path file name based on the runtime env\n#\ndef get_training_filename(data_file_name):    \n    # if running on data bricks\n    if is_databricks():\n        # build the full path file name assuming data brick env\n        full_path_name = \"/FileStore/tables/%s\" % data_file_name\n    # else the data is assumed to be in the same dir as this notebook\n    else:\n        # Assume the student is running on their own computer and load the data\n        # file from the same dir as this notebook\n        full_path_name = data_file_name\n    \n    # return the full path file name to the caller\n    return full_path_name"],
		"metadata": {},
		"outputs": [{
			"metadata": {},
			"output_type": "display_data",
			"data": {
				"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
			}
		}],
		"execution_count": 1
	}, {
		"cell_type": "code",
		"source": ["import re\nimport seaborn as sns\n\ndef shapeOf(df):\n  return (df.count(), len(df.columns))\n\ndef Filter(string): \n  return [str for str in string if re.match(r'[^\\d]+|^', str).group(0) not in ['_c'] ] \n\ndef getDataFrame(file_location):\n  df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").csv(file_location)\n  df = df.select(Filter(df.columns))\n  # df = df.select([col(c).cast(\"double\") for c in df.columns])\n  return df\n\ndef create_Scatter_plot(title, df, x_axis, y_axis):\n  scatter_plot = sns.scatterplot(x=x_axis, y=y_axis, data=df.toPandas())\n  scatter_plot.set(title = title);\n  plt.tight_layout()\n  display(plt.show())\n  return None;\n\ndef find_indices(df, n):\n  #Get the indices of the n highest\n  most_important = sorted(range(len(df)), key=lambda i: df[i])[-n:]\n\n  return most_important\n\ndef print_head_and_shape(df):\n  print(df.toPandas().head())\n  print(\"Shape: \" + str(shapeOf(df)))\n  return None;"],
		"metadata": {},
		"outputs": [{
			"metadata": {},
			"output_type": "display_data",
			"data": {
				"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
			}
		}],
		"execution_count": 2
	}, {
		"cell_type": "code",
		"source": ["raw_lending_club_df = getDataFrame(get_training_filename(\"loan.csv\"))"],
		"metadata": {},
		"outputs": [{
			"metadata": {},
			"output_type": "display_data",
			"data": {
				"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
			}
		}],
		"execution_count": 3
	}, {
		"cell_type": "markdown",
		"source": ["# Process the data\n1. Create a new column called loan_status, where the various late status are bucketed into one status 'Late'\n1. Remove all columns where the number of NA values are greater than 50% of total values."],
		"metadata": {}
	}, {
		"cell_type": "code",
		"source": ["from pyspark.sql.functions import isnan, when, count, col\n\n# Create a new column called loan_status, where the various late status are bucketed into one status 'Late'\n# Also removing all rows where the 'loan_status' is fully paid\nbucketed_df = raw_lending_club_df.filter(col('loan_status').isin(['Late (31-120 days)','Charged Off','Late (16-30 days)','Current']))\nbucketed_df = bucketed_df.withColumn(\"loan_status\", \\\n              when(bucketed_df[\"loan_status\"].isin(['Late (31-120 days)','Late (16-30 days)']),'Late').otherwise(bucketed_df[\"loan_status\"]))"],
		"metadata": {},
		"outputs": [{
			"metadata": {},
			"output_type": "display_data",
			"data": {
				"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
			}
		}],
		"execution_count": 5
	}, {
		"cell_type": "code",
		"source": ["# Write a function to remove columns which contain null values\n\nfrom pyspark.sql import functions as fn\n\ndef drop_null_columns(df):\n    \"\"\"\n    This function drops all columns which contain null values.\n    :param df: A PySpark DataFrame\n    \"\"\"\n    null_counts = df.select([fn.count(fn.when(fn.col(c).isNull()|isnan(fn.col(c)), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n    to_drop = [k for k, v in null_counts.items() if v > 0]\n    df = df.drop(*to_drop)\n    return df"],
		"metadata": {},
		"outputs": [{
			"metadata": {},
			"output_type": "display_data",
			"data": {
				"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
			}
		}],
		"execution_count": 6
	}, {
		"cell_type": "code",
		"source": ["# Remove all columns where the number of NA values are greater than 50% of total values.\n#Creating a dataframe which has the count of Nas of each column\ncheckna = bucketed_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in bucketed_df.columns])\n\n#Selecting the columns with NA values not greater than 50%\nNo_of_rows = bucketed_df.count()\ncheckna_greater_than_50 = checkna.select([when(fn.col(c)<(No_of_rows*0.50),c).alias(c) for c in checkna.columns])\n\n# Using the function to find the list of columns with less than 50%Na values\nfinal_cols = drop_null_columns(checkna_greater_than_50)\nprocessed_lending_club_df = bucketed_df.select([fn.col(c) for c in final_cols.columns])"],
		"metadata": {},
		"outputs": [{
			"metadata": {},
			"output_type": "display_data",
			"data": {
				"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
			}
		}],
		"execution_count": 7
	}, {
		"cell_type": "markdown",
		"source": ["# Process columns with indices from 50 to 75\n1. Select * columns with indices from 50 to 75\n1. Replace NA values with median values"],
		"metadata": {}
	}, {
		"cell_type": "code",
		"source": ["import pandas as pd\nfrom pyspark.sql.types import *\n\n# Select * columns with indices from 50 to 75\npart3 = processed_lending_club_df.select(processed_lending_club_df.columns[51:76:1])\n\n# Convert all data in columns to integers\npart3 = part3.select([col(c).cast(\"integer\") for c in part3.columns])"],
		"metadata": {},
		"outputs": [{
			"metadata": {},
			"output_type": "display_data",
			"data": {
				"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
			}
		}],
		"execution_count": 9
	}, {
		"cell_type": "code",
		"source": ["part3.printSchema()"],
		"metadata": {},
		"outputs": [{
			"metadata": {},
			"output_type": "display_data",
			"data": {
				"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- open_il_12m: integer (nullable = true)\n-- open_il_24m: integer (nullable = true)\n-- mths_since_rcnt_il: integer (nullable = true)\n-- total_bal_il: integer (nullable = true)\n-- il_util: integer (nullable = true)\n-- open_rv_12m: integer (nullable = true)\n-- open_rv_24m: integer (nullable = true)\n-- max_bal_bc: integer (nullable = true)\n-- all_util: integer (nullable = true)\n-- total_rev_hi_lim: integer (nullable = true)\n-- inq_fi: integer (nullable = true)\n-- total_cu_tl: integer (nullable = true)\n-- inq_last_12m: integer (nullable = true)\n-- acc_open_past_24mths: integer (nullable = true)\n-- avg_cur_bal: integer (nullable = true)\n-- bc_open_to_buy: integer (nullable = true)\n-- bc_util: integer (nullable = true)\n-- chargeoff_within_12_mths: integer (nullable = true)\n-- delinq_amnt: integer (nullable = true)\n-- mo_sin_old_il_acct: integer (nullable = true)\n-- mo_sin_old_rev_tl_op: integer (nullable = true)\n-- mo_sin_rcnt_rev_tl_op: integer (nullable = true)\n-- mo_sin_rcnt_tl: integer (nullable = true)\n-- mort_acc: integer (nullable = true)\n-- mths_since_recent_bc: integer (nullable = true)\n\n</div>"]
			}
		}],
		"execution_count": 10
	}, {
		"cell_type": "code",
		"source": [""],
		"metadata": {},
		"outputs": [],
		"execution_count": 11
	}],
	"metadata": {
		"name": "Data cleaning",
		"notebookId": 2055885757584465
	},
	"nbformat": 4,
	"nbformat_minor": 0
}
